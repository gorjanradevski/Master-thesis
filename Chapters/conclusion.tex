\chapter{Conclusion}
\label{cha:conclusion}
In this thesis, I propose \textit{Siamese multi-hop attention}, a deep learning architecture for image-text matching. My main contribution is extending the work of \citet{lin2017structured} for the image-text matching problem. I carry out a comprehensive empirical analysis to emphasize that using multiple hops of attention is essential for image-text matching. By visualizing the image-text matching, we can conclude that the model learns to attend on the essential parts of the image and the sentence while neglecting the rest. Moreover, I propose using a variant of the multi-hop attention called \textit{siamese multi-hop attention}, where the visual and textual attention have tied weights. In addition to that, I conduct experiments to prove that the less memory demanding siamese variant is guaranteed to perform at least as good as the one that uses separate weights for the visual and textual attention. Consequently, all experiments conducted use the \textit{siamese multi-hop attention}. This raises an opportunity to extend this work in a direction where the knowledge from pre-trained attention weights is transferred across modalities to achieve multimodal transfer learning.\endgraf
The industrial application of such deep learning architecture is incredibly broad. So far, the industry is flooded with algorithms that can perform information retrieval in the text-text or image-image cases. However, to the best of my knowledge, a cross-modal retrieval algorithm is yet to be applied in a commercial application. Therefore, the \textit{Siamese multi-hop attention} deep learning architecture can operate within any information retrieval system where the queries submitted by the users are textual, and the database entries are images or vice versa.
%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "thesis"
%%% End: 
