\chapter{Introduction}
\label{cha:intro}

\section{The problem of image-text matching}
In this thesis, the problem of multimodal matching in the image-text case is studied. Image-text matching plays an essential role for image-text retrieval (Retrieving sentences given an image query) and text-image retrieval (Retrieving images given an image query). Recently, a variety of methods that attempt to solve the image-text matching problem have been proposed. The methods generally fall into two categories:
\begin{itemize}
    \item One-to-one matching \cite{kiros2014unifying, frome2013devise, ma2015multimodal, mao2014explain, klein2015associating, faghri2017vse++, wang2018learning, socher2014grounded}: Methods where a global representation is extracted from both modalities and matched using a similarity measure.
    \item Many-to-many matching \cite{nam2017dual, lee2018stacked, karpathy2014deep, karpathy2015deep, huang2017instance}: Methods where a sequence of local representations are extracted from both modalities, and the global similarity is computed as an average of the local similarities.
\end{itemize}
EXPLAIN WHY THE ONE-TO-ONE MATCHING METHODS DON'T DO A GOOD JOB AND WHY THE MANY-TO-MANY METHODS ARE AN EXAGERATION OF HOW A PERSON WILL DO IMAGE-TEXT MATCHING.
\section{Attention mechanism}
The essential component of the \textit{Siamese multi-hop attention} is the attention mechanism \cite{bahdanau2014neural, xu2015show}. Earlier variants of the attention mechanism applied in neural machine translation \cite{bahdanau2014neural} and in neural caption generation \cite{xu2015show} limit the number of attention hops to a single one. A later extension is the structured self-attention \cite{lin2017structured} which is an augmented version of the standard attention mechanism that extends the single-hop attention to a multi-hop one. In this thesis, I start from the premise that multi-step attention is crucial to do an effective image-text matching. In regards to that, the contributions of this thesis are the following:
\begin{itemize}
    \item I extend the \textit{Structured self-attention} \cite{lin2017structured} for the image-text matching problem. I conduct a series of ablation studies to prove that multi-hop attention is necessary to find all alignments between an image and a sentence.
    \item I empirically prove that using multiple hops of attention on its own is not enough for the model to leverage the increased capacity. As a result, the attention hops diversification term \cite{lin2017structured} is implemented for the model to make use of multi-hop attention.
    \item The two branch \textit{multi-hop attention} is merged together in one attention block trained jointly for both modalities. Namely, the \textit{Siamese multi-hop attention} ties the attention weights for both the image and sentence pathway of the model. This is followed by an ablation study to demonstrate that the \textit{multi-hop attention} learns to jointly \textit{pay attention} to both modalities at once.
\end{itemize}

\section{Transfer learning}\label{sec: transfer}
Transfer learning is a method where weights from a deep learning model trained on task \textit{A}, involving a feature space $X_A$ and a label space $Y_A$, are transferred to a different deep learning model to perform on task \textit{B} with feature space $X_B$ and label space $Y_B$ where $A \neq B$. By doing so, the receiving model can make use of the knowledge from the model trained on task \textit{A}. Moreover, transfer learning is particularly useful when the domains of task \textit{A} and task \textit{B} are similar, as is the case for the problem being solved in this thesis.\endgraf
Due to the nature and size of the image-text matching datasets, in this thesis, I make heavy use of transfer learning. Compared to other image-text matching approaches where knowledge is transferred to the image encoder, here knowledge is transferred from pre-trained models to both the image and sentence encoder.\endgraf
To summarize, with the addition of transfer learning on the sentence encoder branch, the final contributions of this thesis are:
\begin{itemize}
    \item Compared to other methods for image-text matching, where knowledge from pre-trained models is transferred to image encoder branch, \textit{Siamese multi-hop attention} makes use of transfer learning on the sentence encoder branch as well.
    \item The \textit{Siamese multi-hop attention} model, with the addition of transferred knowledge to the sentence encoder branch, demonstrates robustness and achieves results competitive to the state-of-the-art on \textit{Pascal1k}, \textit{Flickr8k}, and \textit{Flickr30k} datasets. Furthermore, the \textit{Siamese multi-hop attention} model is interpretable and comes with a feature to visualize the multi-step process the model partakes to embed both modalities in a joint latent space.
\end{itemize}
