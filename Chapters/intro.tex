\chapter{Introduction}
\label{cha:intro}

\section{Image-text matching}
In this thesis, the problem of image-text multimodal matching is studied. Image-text matching plays an essential role for sentence retrieval (retrieving sentences given an image query) and image retrieval (retrieving images given a sentence query). Recently, a variety of methods that attempt to solve the image-text matching problem have been proposed. The methods generally fall into two categories:
\begin{itemize}
    \item One-to-one matching \cite{kiros2014unifying, frome2013devise, ma2015multimodal, mao2014explain, klein2015associating, faghri2017vse++, wang2018learning, socher2014grounded}: Methods where a global representation is extracted from both modalities and matched using a similarity measure.
    \item Many-to-many matching \cite{nam2017dual, lee2018stacked, karpathy2014deep, karpathy2015deep, huang2017instance}: Methods where a sequence of local representations are extracted from both modalities, and the global similarity is computed as an average of the local similarities.
\end{itemize}
In this thesis, I argue that the methodology employed by the one-to-one matching methods is not sophisticated enough to consider all alignments between an image and a sentence. On the other hand, the many-to-many methods take upon an approach which amplifies the complexity of the image-text matching problem.\endgraf
Finally, the \textit{Siamese multi-hop attention} model tries to bridge the gap between the one-to-one and the many-to-many matching methods. The modus operandi of \textit{SMHA} is to leverage the simplicity of the one-to-one matching methods while taking advantage of the comprehensive methodology the many-to-many matching methods employ. To do so, \textit{SMHA} employs a multi-step process in an iterative manner, where a global representation is extracted from both modalities multiple times. Each time the representations are extracted, \textit{SMHA} focuses on different aspects of the modalities, thus searching for all possible correlations that may exist between the image and the text.

\section{Attention mechanism}

\begin{comment}
The essential component of the \textit{Siamese multi-hop attention} is the attention mechanism \cite{bahdanau2014neural, xu2015show}. Earlier variants of the attention mechanism applied in neural machine translation \cite{bahdanau2014neural} and in neural caption generation \cite{xu2015show} limit the number of attention hops to a single one. A later extension is the structured self-attention \cite{lin2017structured}, which is an augmented version of the standard attention mechanism that extends the single-hop attention to a multi-hop one. In this thesis, I start from the premise that multi-hop attention is crucial for successful image-text matching. In regards to that, the contributions of this thesis are the following:
\end{comment}


The essential component of the \textit{Siamese multi-hop attention} is the attention mechanism \cite{bahdanau2014neural, xu2015show}. Earlier variants of the attention mechanism were applied in neural machine translation \cite{bahdanau2014neural} and in neural caption generation \cite{xu2015show}, where attention is applied to associate two sources of information. Later, \citet{cheng2016long, parikh2016decomposable, yang2016hierarchical} implemented self-attention, an attention variant used in conjunction with a recurrent neural network to compute a single linear combination of the hidden states, and thus represent the sequence. Structured self-attention \cite{lin2017structured}, is an augmented version of self-attention which argues that computing a single linear combination is not sufficient, and extends the single-hop attention to a multi-hop one. In this thesis, I start from the premise that multi-hop attention is crucial for successful image-text matching. In regards to that, the contributions of this thesis are the following:
\begin{itemize}
    \item I expand the \textit{structured self-attention} \cite{lin2017structured} for the image-text matching problem. I conduct a series of ablation studies to prove that multi-hop attention is necessary to find all alignments between an image and a sentence.
    \item I empirically prove that using multiple hops of attention on its own is not enough for the model to leverage the increased capacity. As a result, a penalization term \cite{lin2017structured} is implemented to enforce diversity between the attention hops, and push the model towards fully utilizing the multi-hop attention.
\end{itemize}

\section{Siamese networks}
A siamese neural network \cite{bromley1994signature} consists of twin networks that have tied weights. The siamese neural networks were firstly used by \citet{bromley1994signature} to solve the challenge of signature verification, and now are the de facto deep neural network architecture for face verification \cite{taigman2014deepface}. Due to the tied weights, it is guaranteed that two highly similar inputs can not be embedded in different locations in the joint latent space. Moreover, the twin networks compute the same function, so even if the inputs are switched between the twin networks, the output remains the same, thus making the siamese neural network symmetrical. However, the success of the siamese neural networks has been purely related to unimodal matching, and to the best of my knowledge, no study has attempted to leverage a siamese architecture for multimodal matching. On the other hand, the contribution of this thesis is the following:
\begin{itemize}
   \item The two branch \textit{multi-hop attention} is merged in one attention module trained jointly for both modalities. Namely, the \textit{Siamese multi-hop attention} ties the attention weights for both the image and sentence pathway of the model.
   \item  An ablation study is carried out to demonstrate that the less memory demanding \textit{siamese multi-hop attention} performs  on par with the \textit{multi-hop attention}, and learns to pay attention to both modalities at once.
\end{itemize}


\section{Transfer learning}\label{sec: transfer}
Transfer learning is a method where weights from a deep learning model trained on task \textit{A}, involving a feature space $X_A$ and a label space $Y_A$, are transferred to a different deep learning model to perform on task \textit{B} with feature space $X_B$ and label space $Y_B$ where $A \neq B$. By doing so, the receiving model can make use of the knowledge from the model trained on task \textit{A}. Moreover, transfer learning is particularly useful when the domains of task \textit{A} and task \textit{B} are similar, as is the case for the problem being solved in this thesis.\endgraf
Due to the nature and size of the image-text matching datasets, in this thesis, I make heavy use of transfer learning. Compared to other image-text matching approaches where knowledge is transferred to the image encoder, here knowledge is transferred from pre-trained models to both the image and sentence encoder.\endgraf
To summarize, with the addition of transfer learning to the sentence encoder branch, the final contributions of this thesis are:
\begin{itemize}
    \item Compared to other methods for image-text matching, where knowledge from pre-trained models is transferred only to the image encoder branch, \textit{Siamese multi-hop attention} makes use of transfer learning on both the image encoder and the sentence encoder branch.
    \item The \textit{Siamese multi-hop attention} model, with the addition of transferred knowledge to the sentence encoder branch, demonstrates robustness and achieves results competitive to the state-of-the-art on \textit{Pascal1k}, \textit{Flickr8k}, and \textit{Flickr30k} datasets. Furthermore, the \textit{Siamese multi-hop attention} model is interpretable and can visualize the multi-step process it partakes to embed the modalities in a joint latent space.
\end{itemize}
