\chapter{Introduction}
\label{cha:intro}

\section{The problem of image-text matching}
In this thesis, the problem of multimodal matching in the image-text case is studied. Image-text matching plays an essential role for image-text retrieval (retrieving sentences given an image query) and text-image retrieval (retrieving images given a sentence query). Recently, a variety of methods that attempt to solve the image-text matching problem have been proposed. The methods generally fall into two categories:
\begin{itemize}
    \item One-to-one matching \cite{kiros2014unifying, frome2013devise, ma2015multimodal, mao2014explain, klein2015associating, faghri2017vse++, wang2018learning, socher2014grounded}: Methods where a global representation is extracted from both modalities and matched using a similarity measure.
    \item Many-to-many matching \cite{nam2017dual, lee2018stacked, karpathy2014deep, karpathy2015deep, huang2017instance}: Methods where a sequence of local representations are extracted from both modalities, and the global similarity is computed as an average of the local similarities.
\end{itemize}
In this thesis, I argue that the methodology employed by the one-to-one matching methods is not sophisticated enough to consider all alignments between an image and a sentence. On the other hand, the many-to-many methods take upon an approach which amplifies the complexity of the image-text matching problem.\endgraf
Finally, the \textit{Siamese multi-hop attention} model tries to bridge the gap between the one-to-one and the many-to-many matching methods. The modus operandi of \textit{SMHA} is to leverage the simplicity of the one-to-one matching methods while taking advantage of the comprehensive methodology the many-to-many matching methods employ. To do so, \textit{SMHA} employs a multi-step process in an iterative manner, where a global representation is extracted from both modalities multiple times. Each time the representations are extracted, \textit{SMHA} focuses on different aspects of the modalities, thus searching for all possible correlations that may exist between the image and the text.

\section{Attention mechanism}
The essential component of the \textit{Siamese multi-hop attention} is the attention mechanism \cite{bahdanau2014neural, xu2015show}. Earlier variants of the attention mechanism applied in neural machine translation \cite{bahdanau2014neural} and in neural caption generation \cite{xu2015show} limit the number of attention hops to a single one. A later extension is the structured self-attention \cite{lin2017structured}, which is an augmented version of the standard attention mechanism that extends the single-hop attention to a multi-hop one. In this thesis, I start from the premise that multi-hop attention is crucial to do an successful image-text matching. In regards to that, the contributions of this thesis are the following:
\begin{itemize}
    \item I extend the \textit{structured self-attention} \cite{lin2017structured} for the image-text matching problem. I conduct a series of ablation studies to prove that multi-hop attention is necessary to find all alignments between an image and a sentence.
    \item I empirically prove that using multiple hops of attention on its own is not enough for the model to leverage the increased capacity. As a result, the attention hops diversification term \cite{lin2017structured} is implemented for the model to make use of multi-hop attention.
    \item The two branch \textit{multi-hop attention} is merged in one attention module trained jointly for both modalities. Namely, the \textit{Siamese multi-hop attention} ties the attention weights for both the image and sentence pathway of the model. An ablation study is carried out to demonstrate that the \textit{multi-hop attention} learns to pay attention to both modalities at once jointly.
\end{itemize}

\section{Transfer learning}\label{sec: transfer}
Transfer learning is a method where weights from a deep learning model trained on task \textit{A}, involving a feature space $X_A$ and a label space $Y_A$, are transferred to a different deep learning model to perform on task \textit{B} with feature space $X_B$ and label space $Y_B$ where $A \neq B$. By doing so, the receiving model can make use of the knowledge from the model trained on task \textit{A}. Moreover, transfer learning is particularly useful when the domains of task \textit{A} and task \textit{B} are similar, as is the case for the problem being solved in this thesis.\endgraf
Due to the nature and size of the image-text matching datasets, in this thesis, I make heavy use of transfer learning. Compared to other image-text matching approaches where knowledge is transferred to the image encoder, here knowledge is transferred from pre-trained models to both the image and sentence encoder.\endgraf
To summarize, with the addition of transfer learning to the sentence encoder branch, the final contributions of this thesis are:
\begin{itemize}
    \item Compared to other methods for image-text matching, where knowledge from pre-trained models is transferred only to the image encoder branch, \textit{Siamese multi-hop attention} makes use of transfer learning on both the image encoder and the sentence encoder branch.
    \item The \textit{Siamese multi-hop attention} model, with the addition of transferred knowledge to the sentence encoder branch, demonstrates robustness and achieves results competitive to the state-of-the-art on \textit{Pascal1k}, \textit{Flickr8k}, and \textit{Flickr30k} datasets. Furthermore, the \textit{Siamese multi-hop attention} model is interpretable and can visualize the multi-step process it partakes to embed both modalities in a joint latent space.
\end{itemize}
